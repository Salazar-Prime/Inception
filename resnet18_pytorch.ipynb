{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- (tensor([[[-1.4158, -1.3302, -1.3473,  ..., -0.4739, -0.4739, -0.4568],\n",
      "         [-1.4500, -1.5699, -1.5699,  ..., -0.4568, -0.4739, -0.4226],\n",
      "         [-1.3987, -1.3815, -1.1589,  ..., -0.4226, -0.3883, -0.3369],\n",
      "         ...,\n",
      "         [-0.2513, -0.5253, -0.9705,  ..., -1.6213, -1.6555, -1.5357],\n",
      "         [-0.2684, -0.4739, -0.9534,  ..., -1.3302, -1.3987, -1.4672],\n",
      "         [-0.3027, -0.3883, -0.8164,  ..., -1.2445, -1.2617, -1.2788]],\n",
      "\n",
      "        [[-1.3704, -1.2829, -1.3004,  ...,  0.3803,  0.3803,  0.3978],\n",
      "         [-1.4580, -1.5455, -1.5455,  ...,  0.3978,  0.3803,  0.4328],\n",
      "         [-1.4405, -1.3880, -1.1604,  ...,  0.4328,  0.4678,  0.5203],\n",
      "         ...,\n",
      "         [ 0.3277,  0.0476, -0.2675,  ..., -1.7031, -1.6681, -1.4580],\n",
      "         [ 0.2927,  0.0651, -0.3375,  ..., -1.5805, -1.5805, -1.5980],\n",
      "         [ 0.0126,  0.1176, -0.2675,  ..., -1.4930, -1.5105, -1.5280]],\n",
      "\n",
      "        [[-1.2467, -1.1421, -1.1596,  ..., -0.4973, -0.5147, -0.4798],\n",
      "         [-1.3861, -1.4384, -1.4036,  ..., -0.4973, -0.4973, -0.4624],\n",
      "         [-1.4036, -1.3164, -1.0376,  ..., -0.4624, -0.4275, -0.3753],\n",
      "         ...,\n",
      "         [-0.5495, -1.0376, -1.5604,  ..., -1.5081, -1.5430, -1.5604],\n",
      "         [-0.5321, -0.9678, -1.5081,  ..., -1.5256, -1.6476, -1.6650],\n",
      "         [-0.7238, -0.7761, -1.1596,  ..., -1.5256, -1.5604, -1.5604]]]), 0)\n",
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from io import BufferedReader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = \"weed_data\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), \n",
    "                                           transform=data_transforms[x])\n",
    "                 for x in [\"train\", \"val\", \"test\"]}\n",
    "temp = image_datasets[\"train\"]\n",
    "# print(\"-----------------------------\", os.path.join(data_dir, \"train\"))  \n",
    "print(\"-----------------------------\", temp[0])       \n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, \n",
    "                                              shuffle=True, num_workers=4)\n",
    "              for x in [\"train\", \"val\", \"test\"]}\n",
    "\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\", \"test\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[\"train\"]))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "      \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "                model.train()  # set model to training mode\n",
    "            else:\n",
    "                model.eval()  # set model to evaulate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Interate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Backward + optimize only if in training mode\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if phase == \"val\":\n",
    "                val_loss.append(epoch_loss)\n",
    "                val_acc.append(float(epoch_acc.to(\"cpu\").numpy()))\n",
    "            else:\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(float(epoch_acc.to(\"cpu\").numpy()))\n",
    "        print('{} seconds'.format(time.time() - t0))\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best val Acc: {:4f}\".format(best_acc))\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    with open('./accuracy.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            \"training\": train_acc,\n",
    "            \"validation\": val_acc\n",
    "        }, f)\n",
    "    with open('./loss.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            \"training\": train_loss,\n",
    "            \"validation\": val_loss\n",
    "        }, f)\n",
    "\n",
    "    torch.save(model, 'weed_data.pth')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer\n",
    "\n",
    "# for vgg16\n",
    "# model_ft = models.vgg16(pretrained=True)\n",
    "# num_ftrs = model_ft.classifier[0].out_features\n",
    "\n",
    "# for resnet 18\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# for inception\n",
    "# model_ft = models.inception_v3(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 150, 150]             128\n",
      "              ReLU-3         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-4           [-1, 64, 75, 75]               0\n",
      "            Conv2d-5           [-1, 64, 75, 75]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 75, 75]             128\n",
      "              ReLU-7           [-1, 64, 75, 75]               0\n",
      "            Conv2d-8           [-1, 64, 75, 75]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 75, 75]             128\n",
      "             ReLU-10           [-1, 64, 75, 75]               0\n",
      "       BasicBlock-11           [-1, 64, 75, 75]               0\n",
      "           Conv2d-12           [-1, 64, 75, 75]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 75, 75]             128\n",
      "             ReLU-14           [-1, 64, 75, 75]               0\n",
      "           Conv2d-15           [-1, 64, 75, 75]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 75, 75]             128\n",
      "             ReLU-17           [-1, 64, 75, 75]               0\n",
      "       BasicBlock-18           [-1, 64, 75, 75]               0\n",
      "           Conv2d-19          [-1, 128, 38, 38]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 38, 38]             256\n",
      "             ReLU-21          [-1, 128, 38, 38]               0\n",
      "           Conv2d-22          [-1, 128, 38, 38]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 38, 38]             256\n",
      "           Conv2d-24          [-1, 128, 38, 38]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 38, 38]             256\n",
      "             ReLU-26          [-1, 128, 38, 38]               0\n",
      "       BasicBlock-27          [-1, 128, 38, 38]               0\n",
      "           Conv2d-28          [-1, 128, 38, 38]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 38, 38]             256\n",
      "             ReLU-30          [-1, 128, 38, 38]               0\n",
      "           Conv2d-31          [-1, 128, 38, 38]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 38, 38]             256\n",
      "             ReLU-33          [-1, 128, 38, 38]               0\n",
      "       BasicBlock-34          [-1, 128, 38, 38]               0\n",
      "           Conv2d-35          [-1, 256, 19, 19]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 19, 19]             512\n",
      "             ReLU-37          [-1, 256, 19, 19]               0\n",
      "           Conv2d-38          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 19, 19]             512\n",
      "           Conv2d-40          [-1, 256, 19, 19]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 19, 19]             512\n",
      "             ReLU-42          [-1, 256, 19, 19]               0\n",
      "       BasicBlock-43          [-1, 256, 19, 19]               0\n",
      "           Conv2d-44          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 19, 19]             512\n",
      "             ReLU-46          [-1, 256, 19, 19]               0\n",
      "           Conv2d-47          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 19, 19]             512\n",
      "             ReLU-49          [-1, 256, 19, 19]               0\n",
      "       BasicBlock-50          [-1, 256, 19, 19]               0\n",
      "           Conv2d-51          [-1, 512, 10, 10]       1,179,648\n",
      "      BatchNorm2d-52          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-53          [-1, 512, 10, 10]               0\n",
      "           Conv2d-54          [-1, 512, 10, 10]       2,359,296\n",
      "      BatchNorm2d-55          [-1, 512, 10, 10]           1,024\n",
      "           Conv2d-56          [-1, 512, 10, 10]         131,072\n",
      "      BatchNorm2d-57          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-58          [-1, 512, 10, 10]               0\n",
      "       BasicBlock-59          [-1, 512, 10, 10]               0\n",
      "           Conv2d-60          [-1, 512, 10, 10]       2,359,296\n",
      "      BatchNorm2d-61          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-62          [-1, 512, 10, 10]               0\n",
      "           Conv2d-63          [-1, 512, 10, 10]       2,359,296\n",
      "      BatchNorm2d-64          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-65          [-1, 512, 10, 10]               0\n",
      "       BasicBlock-66          [-1, 512, 10, 10]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 4]           2,052\n",
      "================================================================\n",
      "Total params: 11,178,564\n",
      "Trainable params: 11,178,564\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.03\n",
      "Forward/backward pass size (MB): 114.26\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 157.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_ft, input_size=(3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.0158 Acc: 0.5370\n",
      "val Loss: 0.4942 Acc: 0.8352\n",
      "7.100767612457275 seconds\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.5231 Acc: 0.8222\n",
      "val Loss: 0.2784 Acc: 0.9121\n",
      "6.805584192276001 seconds\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.3798 Acc: 0.8333\n",
      "val Loss: 0.1893 Acc: 0.9121\n",
      "7.0894999504089355 seconds\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.7761 Acc: 0.7556\n",
      "val Loss: 0.2012 Acc: 0.9231\n",
      "7.018364429473877 seconds\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.4183 Acc: 0.8370\n",
      "val Loss: 0.1102 Acc: 0.9560\n",
      "6.483587265014648 seconds\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.4511 Acc: 0.8370\n",
      "val Loss: 0.1391 Acc: 0.9560\n",
      "7.1598289012908936 seconds\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.4027 Acc: 0.8593\n",
      "val Loss: 0.1451 Acc: 0.9451\n",
      "6.829798698425293 seconds\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.1791 Acc: 0.9333\n",
      "val Loss: 0.0950 Acc: 0.9560\n",
      "6.742856740951538 seconds\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.3037 Acc: 0.8741\n",
      "val Loss: 0.1008 Acc: 0.9560\n",
      "6.944694995880127 seconds\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.2336 Acc: 0.9259\n",
      "val Loss: 0.1297 Acc: 0.9560\n",
      "7.707035779953003 seconds\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.2549 Acc: 0.9074\n",
      "val Loss: 0.0943 Acc: 0.9560\n",
      "6.708201169967651 seconds\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.2244 Acc: 0.9259\n",
      "val Loss: 0.0923 Acc: 0.9670\n",
      "6.260458707809448 seconds\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.2649 Acc: 0.9000\n",
      "val Loss: 0.0801 Acc: 0.9670\n",
      "7.002263784408569 seconds\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.2353 Acc: 0.9185\n",
      "val Loss: 0.0872 Acc: 0.9670\n",
      "6.923498868942261 seconds\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.1397 Acc: 0.9444\n",
      "val Loss: 0.0689 Acc: 0.9780\n",
      "7.436083793640137 seconds\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.1739 Acc: 0.9444\n",
      "val Loss: 0.0883 Acc: 0.9670\n",
      "6.83210825920105 seconds\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.1663 Acc: 0.9481\n",
      "val Loss: 0.0894 Acc: 0.9670\n",
      "7.026760816574097 seconds\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.2213 Acc: 0.9222\n",
      "val Loss: 0.1172 Acc: 0.9560\n",
      "6.649181127548218 seconds\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.2035 Acc: 0.9111\n",
      "val Loss: 0.0984 Acc: 0.9670\n",
      "7.802167654037476 seconds\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.2416 Acc: 0.9222\n",
      "val Loss: 0.1241 Acc: 0.9560\n",
      "6.999608039855957 seconds\n",
      "\n",
      "Training complete in 2m 20s\n",
      "Best val Acc: 0.978022\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "PATH = 'model-resnet18-final.h5'\n",
    "torch.save(model_ft, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cocklebur       1.00      1.00      1.00        17\n",
      "     foxtail       0.88      1.00      0.93        14\n",
      "     pigweed       0.97      0.97      0.97        34\n",
      "     ragweed       0.95      0.87      0.91        23\n",
      "\n",
      "    accuracy                           0.95        88\n",
      "   macro avg       0.95      0.96      0.95        88\n",
      "weighted avg       0.96      0.95      0.95        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "def print_confusion_matrix(model):\n",
    "    pred = []\n",
    "    true = []\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[\"test\"]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds = preds.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            preds = np.reshape(preds, (len(preds), 1))\n",
    "            labels = np.reshape(labels, (len(preds), 1))\n",
    "            for i in range(len(preds)):\n",
    "                pred.append(class_names[int(preds[i])])\n",
    "                true.append(class_names[int(labels[i])])\n",
    "    with open('./preds.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            \"true\": true,\n",
    "            \"pred\": pred,\n",
    "            \"classes\": class_names\n",
    "        }, f)\n",
    "\n",
    "    \n",
    "    print(classification_report(true, pred, class_names))\n",
    "    return confusion_matrix(true, pred, class_names)\n",
    "\n",
    "cm = print_confusion_matrix(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for plots et al.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "row_sums = cm.sum(axis=1)\n",
    "cm = cm / row_sums\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = ['cocklebur','foxtail','pigweed','ragweed'], columns = ['cocklebur','foxtail','pigweed','ragweed'])\n",
    "# print(df_cm)\n",
    "\n",
    "# flights = df_cm.pivot(\"month\", \"year\", \"passengers\")\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.title('ResNet18')\n",
    "sn.heatmap(df_cm, annot=True, fmt='0.0%', cbar=False)\n",
    "plt.savefig('ResNet18.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
