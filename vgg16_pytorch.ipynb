{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- (tensor([[[-0.0972, -0.0458, -0.0116,  ..., -0.4397, -0.6965, -0.7993],\n",
      "         [-0.0801, -0.0629, -0.0116,  ...,  0.5707, -0.3712, -0.8164],\n",
      "         [-0.0629, -0.0972,  0.0056,  ...,  0.6906,  0.5022, -0.0287],\n",
      "         ...,\n",
      "         [ 0.0227, -0.1314, -1.3473,  ..., -1.5870, -1.4672, -1.3473],\n",
      "         [ 0.0741, -0.6623, -1.6898,  ..., -1.5870, -1.3987, -1.3302],\n",
      "         [-0.6623, -0.9363, -1.1075,  ..., -1.4158, -1.3987, -1.3987]],\n",
      "\n",
      "        [[ 0.7304,  0.7829,  0.8179,  ..., -0.6527, -0.8978, -1.0028],\n",
      "         [ 0.7479,  0.7654,  0.8179,  ...,  0.3803, -0.5826, -1.0378],\n",
      "         [ 0.7654,  0.7304,  0.8354,  ...,  0.5028,  0.3102, -0.2325],\n",
      "         ...,\n",
      "         [ 0.6779,  0.5203, -0.8803,  ..., -1.0378, -0.8102, -0.6001],\n",
      "         [ 0.5028, -0.2325, -1.3880,  ..., -0.8803, -0.6702, -0.6001],\n",
      "         [-0.5651, -0.7227, -0.8627,  ..., -0.6877, -0.6702, -0.6702]],\n",
      "\n",
      "        [[-0.1312, -0.0790, -0.0441,  ..., -0.6541, -1.0027, -1.1944],\n",
      "         [-0.1138, -0.0964, -0.0441,  ...,  0.3219, -0.6541, -1.1247],\n",
      "         [-0.0964, -0.1312, -0.0267,  ...,  0.3916,  0.2522, -0.2707],\n",
      "         ...,\n",
      "         [-0.3753, -0.4101, -1.3339,  ..., -1.6650, -1.5953, -1.4907],\n",
      "         [-0.2881, -0.9504, -1.5953,  ..., -1.6999, -1.4907, -1.4210],\n",
      "         [-1.1073, -1.2119, -1.1944,  ..., -1.5256, -1.5081, -1.5256]]]), 0)\n",
      "False\n",
      "<class 'torch.device'>\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Kristiaan Hector | Varun Aggarwal | Aaron Etienne\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from io import BufferedReader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = \"weed_data\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), \n",
    "                                           transform=data_transforms[x])\n",
    "                 for x in [\"train\", \"val\", \"test\"]}\n",
    "temp = image_datasets[\"train\"]\n",
    "# print(\"-----------------------------\", os.path.join(data_dir, \"train\"))  \n",
    "print(\"-----------------------------\", temp[0])       \n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, \n",
    "                                              shuffle=True, num_workers=4)\n",
    "              for x in [\"train\", \"val\", \"test\"]}\n",
    "\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\", \"test\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.device)\n",
    "device = torch.device(\"gpu:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[\"train\"]))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "                model.train()  # set model to training mode\n",
    "            else:\n",
    "                model.eval()  # set model to evaulate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Interate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Backward + optimize only if in training mode\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if phase == \"val\":\n",
    "                val_loss.append(epoch_loss)\n",
    "                val_acc.append(float(epoch_acc.to(\"cpu\").numpy()))\n",
    "            else:\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(float(epoch_acc.to(\"cpu\").numpy()))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best val Acc: {:4f}\".format(best_acc))\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    with open('./accuracy.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            \"training\": train_acc,\n",
    "            \"validation\": val_acc\n",
    "        }, f)\n",
    "    with open('./loss.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            \"training\": train_loss,\n",
    "            \"validation\": val_loss\n",
    "        }, f)\n",
    "\n",
    "    torch.save(model, 'weed_data.pth')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer\n",
    "\n",
    "# for vgg16\n",
    "model_ft = models.vgg16(pretrained=True)\n",
    "num_ftrs = model_ft.classifier[0].out_features\n",
    "\n",
    "# for resnet 18\n",
    "# model_ft = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# for inception\n",
    "# model_ft = models.inception_v3(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 300, 300]           1,792\n",
      "              ReLU-2         [-1, 64, 300, 300]               0\n",
      "            Conv2d-3         [-1, 64, 300, 300]          36,928\n",
      "              ReLU-4         [-1, 64, 300, 300]               0\n",
      "         MaxPool2d-5         [-1, 64, 150, 150]               0\n",
      "            Conv2d-6        [-1, 128, 150, 150]          73,856\n",
      "              ReLU-7        [-1, 128, 150, 150]               0\n",
      "            Conv2d-8        [-1, 128, 150, 150]         147,584\n",
      "              ReLU-9        [-1, 128, 150, 150]               0\n",
      "        MaxPool2d-10          [-1, 128, 75, 75]               0\n",
      "           Conv2d-11          [-1, 256, 75, 75]         295,168\n",
      "             ReLU-12          [-1, 256, 75, 75]               0\n",
      "           Conv2d-13          [-1, 256, 75, 75]         590,080\n",
      "             ReLU-14          [-1, 256, 75, 75]               0\n",
      "           Conv2d-15          [-1, 256, 75, 75]         590,080\n",
      "             ReLU-16          [-1, 256, 75, 75]               0\n",
      "        MaxPool2d-17          [-1, 256, 37, 37]               0\n",
      "           Conv2d-18          [-1, 512, 37, 37]       1,180,160\n",
      "             ReLU-19          [-1, 512, 37, 37]               0\n",
      "           Conv2d-20          [-1, 512, 37, 37]       2,359,808\n",
      "             ReLU-21          [-1, 512, 37, 37]               0\n",
      "           Conv2d-22          [-1, 512, 37, 37]       2,359,808\n",
      "             ReLU-23          [-1, 512, 37, 37]               0\n",
      "        MaxPool2d-24          [-1, 512, 18, 18]               0\n",
      "           Conv2d-25          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-26          [-1, 512, 18, 18]               0\n",
      "           Conv2d-27          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-28          [-1, 512, 18, 18]               0\n",
      "           Conv2d-29          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-30          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-31            [-1, 512, 9, 9]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.03\n",
      "Forward/backward pass size (MB): 390.39\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 919.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_ft, input_size=(3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.4309 Acc: 0.3759\n",
      "val Loss: 1.8167 Acc: 0.3763\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.3957 Acc: 0.4489\n",
      "val Loss: 0.7761 Acc: 0.5484\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.8071 Acc: 0.6788\n",
      "val Loss: 0.5754 Acc: 0.8495\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.9282 Acc: 0.6861\n",
      "val Loss: 0.7402 Acc: 0.7097\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.5785 Acc: 0.7956\n",
      "val Loss: 0.2616 Acc: 0.9355\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3899 Acc: 0.8796\n",
      "val Loss: 0.3329 Acc: 0.8925\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2400 Acc: 0.9270\n",
      "val Loss: 0.2336 Acc: 0.9355\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1769 Acc: 0.9307\n",
      "val Loss: 0.2178 Acc: 0.9462\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1283 Acc: 0.9635\n",
      "val Loss: 0.2190 Acc: 0.9462\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1171 Acc: 0.9599\n",
      "val Loss: 0.2037 Acc: 0.9570\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1165 Acc: 0.9635\n",
      "val Loss: 0.1900 Acc: 0.9570\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0985 Acc: 0.9672\n",
      "val Loss: 0.1834 Acc: 0.9677\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0795 Acc: 0.9708\n",
      "val Loss: 0.1887 Acc: 0.9570\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0734 Acc: 0.9818\n",
      "val Loss: 0.1849 Acc: 0.9570\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0796 Acc: 0.9781\n",
      "val Loss: 0.1810 Acc: 0.9570\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0818 Acc: 0.9708\n",
      "val Loss: 0.1796 Acc: 0.9570\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0833 Acc: 0.9745\n",
      "val Loss: 0.1790 Acc: 0.9570\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0546 Acc: 0.9891\n",
      "val Loss: 0.1789 Acc: 0.9570\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0863 Acc: 0.9708\n",
      "val Loss: 0.1789 Acc: 0.9570\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0692 Acc: 0.9672\n",
      "val Loss: 0.1784 Acc: 0.9677\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0661 Acc: 0.9781\n",
      "val Loss: 0.1782 Acc: 0.9677\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9599\n",
      "val Loss: 0.1781 Acc: 0.9677\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0864 Acc: 0.9745\n",
      "val Loss: 0.1777 Acc: 0.9677\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0707 Acc: 0.9818\n",
      "val Loss: 0.1777 Acc: 0.9677\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0912 Acc: 0.9635\n",
      "val Loss: 0.1775 Acc: 0.9677\n",
      "\n",
      "Training complete in 83m 41s\n",
      "Best val Acc: 0.967742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type VGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/salazar/anaconda3/envs/maskrcnnv2/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cocklebur       1.00      0.83      0.91         6\n",
      "     foxtail       1.00      0.93      0.96        14\n",
      "     pigweed       0.97      1.00      0.99        35\n",
      "     ragweed       0.97      1.00      0.99        36\n",
      "\n",
      "    accuracy                           0.98        91\n",
      "   macro avg       0.99      0.94      0.96        91\n",
      "weighted avg       0.98      0.98      0.98        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "def print_confusion_matrix(model):\n",
    "    pred = []\n",
    "    true = []\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[\"test\"]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds = preds.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            preds = np.reshape(preds, (len(preds), 1))\n",
    "            labels = np.reshape(labels, (len(preds), 1))\n",
    "            for i in range(len(preds)):\n",
    "                pred.append(class_names[int(preds[i])])\n",
    "                true.append(class_names[int(labels[i])])\n",
    "    with open('./preds.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            \"true\": true,\n",
    "            \"pred\": pred,\n",
    "            \"classes\": class_names\n",
    "        }, f)\n",
    "\n",
    "    \n",
    "    print(classification_report(true, pred, class_names))\n",
    "    return confusion_matrix(true, pred, class_names)\n",
    "\n",
    "cm = print_confusion_matrix(model_ft)\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for plots et al.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "# row_sums = cm.sum(axis=1)\n",
    "# cm = cm / row_sums\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = ['cocklebur','foxtail','pigweed','ragweed'], columns = ['cocklebur','foxtail','pigweed','ragweed'])\n",
    "# print(df_cm)\n",
    "\n",
    "# flights = df_cm.pivot(\"month\", \"year\", \"passengers\")\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.title('VGG16')\n",
    "sn.heatmap(df_cm, annot=True, cbar=False)\n",
    "plt.savefig('VGG16_pytorch.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
